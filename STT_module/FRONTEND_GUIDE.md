# ğŸ¨ í”„ë¡ íŠ¸ì—”ë“œ í†µí•© ê°€ì´ë“œ

STT ì„œë²„ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì— í†µí•©í•˜ëŠ” ìƒì„¸ ê°€ì´ë“œ

---

## ğŸ“‹ ëª©ì°¨

1. [WebSocket í”„ë¡œí† ì½œ](#-websocket-í”„ë¡œí† ì½œ)
2. [ì˜¤ë””ì˜¤ í˜•ì‹ ìš”êµ¬ì‚¬í•­](#-ì˜¤ë””ì˜¤-í˜•ì‹-ìš”êµ¬ì‚¬í•­)
3. [JavaScript í†µí•© ì˜ˆì œ](#-javascript-í†µí•©-ì˜ˆì œ)
4. [React í†µí•© ì˜ˆì œ](#-react-í†µí•©-ì˜ˆì œ)
5. [Vue.js í†µí•© ì˜ˆì œ](#-vuejs-í†µí•©-ì˜ˆì œ)
6. [ì˜¤ë¥˜ ì²˜ë¦¬](#-ì˜¤ë¥˜-ì²˜ë¦¬)
7. [ì„±ëŠ¥ ìµœì í™”](#-ì„±ëŠ¥-ìµœì í™”)
8. [FAQ](#-faq)

---

## ğŸ”Œ WebSocket í”„ë¡œí† ì½œ

### ì—°ê²° ì—”ë“œí¬ì¸íŠ¸

```
ws://localhost:8003/ws/stt  (.envì—ì„œ ì—”ë“œí¬ì¸íŠ¸ (path) ìˆ˜ì • ê°€ëŠ¥)
```

### ë©”ì‹œì§€ í˜•ì‹

#### í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„

**1. ì˜¤ë””ì˜¤ ì „ì†¡**
```json
{
  "type": "audio",
  "audio": "<base64-encoded-pcm16>"
}
```

**2. ë…¹ìŒ ì¤‘ì§€**
```json
{
  "type": "stop"
}
```

#### ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸

**1. ì‹¤ì‹œê°„ ì „ì‚¬ (ë¸íƒ€)**
```json
{
  "type": "transcript_delta",
  "text": "ì•ˆë…•í•˜",
  "item_id": "item_abc123",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

**2. ì „ì‚¬ ì™„ë£Œ**
```json
{
  "type": "transcript_completed",
  "text": "ì•ˆë…•í•˜ì„¸ìš”",
  "item_id": "item_abc123",
  "timestamp": "2024-01-01T12:00:01.000Z"
}
```

**3. ìŒì„± ê°ì§€ ì‹œì‘ (VAD í™œì„±í™” ì‹œ)**
```json
{
  "type": "speech_started",
  "timestamp": "2024-01-01T12:00:00.000Z"
}
```

**4. ìŒì„± ê°ì§€ ì¢…ë£Œ (VAD í™œì„±í™” ì‹œ)**
```json
{
  "type": "speech_stopped",
  "timestamp": "2024-01-01T12:00:05.000Z"
}
```

**5. ì˜¤ë¥˜**
```json
{
  "type": "error",
  "message": "ì˜¤ë¥˜ ë©”ì‹œì§€"
}
```

**6. ì •ë³´**
```json
{
  "type": "info",
  "message": "ì •ë³´ ë©”ì‹œì§€"
}
```

---

## ğŸ¤ ì˜¤ë””ì˜¤ í˜•ì‹ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ ì‚¬ì–‘

- **í¬ë§·**: PCM16 (16-bit Linear PCM)
- **ìƒ˜í”Œë ˆì´íŠ¸**: 24000 Hz (24kHz) - **ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•¨**
- **ì±„ë„**: 1 (Mono)
- **ì¸ì½”ë”©**: Base64
- **ì—”ë””ì•ˆ**: Little-endian

### ê¶Œì¥ ì„¤ì •

```javascript
const audioConfig = {
  sampleRate: 24000,          // 24kHz (í•„ìˆ˜!)
  channelCount: 1,            // Mono
  echoCancellation: true,     // ì—ì½” ì œê±°
  noiseSuppression: true,     // ë…¸ì´ì¦ˆ ì œê±°
  autoGainControl: true       // ìë™ ê²Œì¸ ì¡°ì ˆ
};
```

### ì˜¤ë””ì˜¤ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```
ë§ˆì´í¬ ì…ë ¥ 
  â†’ MediaStream 
  â†’ AudioContext (24kHz)
  â†’ ScriptProcessor
  â†’ Float32 â†’ Int16 ë³€í™˜
  â†’ Base64 ì¸ì½”ë”©
  â†’ WebSocket ì „ì†¡
```

---

## ğŸ’» JavaScript í†µí•© ì˜ˆì œ

### 1. ê¸°ë³¸ ì„¤ì •

```javascript
// WebSocket ì—°ê²°
const ws = new WebSocket('ws://localhost:8003/ws/stt');

// ì˜¤ë””ì˜¤ ì„¤ì •
const audioConfig = {
  sampleRate: 24000,
  channelCount: 1,
  echoCancellation: true,
  noiseSuppression: true
};
```

### 2. WebSocket ì´ë²¤íŠ¸ ì²˜ë¦¬

```javascript
ws.onopen = () => {
  console.log('âœ… WebSocket ì—°ê²°ë¨');
  startAudioCapture();
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  
  switch (data.type) {
    case 'transcript_delta':
      // ì‹¤ì‹œê°„ ì „ì‚¬ ì—…ë°ì´íŠ¸
      updateTranscriptDelta(data.text);
      break;
      
    case 'transcript_completed':
      // ì™„ë£Œëœ ì „ì‚¬ ì €ì¥
      saveTranscript(data.text);
      break;
      
    case 'speech_started':
      // UI: ìŒì„± ê°ì§€ ì¤‘ í‘œì‹œ
      showRecordingIndicator();
      break;
      
    case 'speech_stopped':
      // UI: ëŒ€ê¸° ìƒíƒœ í‘œì‹œ
      hideRecordingIndicator();
      break;
      
    case 'error':
      // ì˜¤ë¥˜ ì²˜ë¦¬
      handleError(data.message);
      break;
  }
};

ws.onerror = (error) => {
  console.error('âŒ WebSocket ì˜¤ë¥˜:', error);
};

ws.onclose = () => {
  console.log('ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ');
  cleanup();
};
```

### 3. ì˜¤ë””ì˜¤ ìº¡ì²˜ ë° ì „ì†¡

```javascript
let audioContext;
let processor;
let mediaStream;

async function startAudioCapture() {
  try {
    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: audioConfig
    });
    
    // AudioContext ìƒì„± (24kHz!)
    audioContext = new AudioContext({ sampleRate: 24000 });
    
    // MediaStream â†’ AudioContext
    const source = audioContext.createMediaStreamSource(mediaStream);
    
    // ScriptProcessor ìƒì„±
    processor = audioContext.createScriptProcessor(4096, 1, 1);
    
    // ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
    processor.onaudioprocess = (e) => {
      const inputData = e.inputBuffer.getChannelData(0);
      const pcm16 = convertToPCM16(inputData);
      const base64 = arrayBufferToBase64(pcm16.buffer);
      
      // WebSocketìœ¼ë¡œ ì „ì†¡
      if (ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({
          type: 'audio',
          audio: base64
        }));
      }
    };
    
    // AudioContext ì—°ê²°
    source.connect(processor);
    processor.connect(audioContext.destination);
    
    console.log('ğŸ™ï¸ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘');
    
  } catch (error) {
    console.error('âŒ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì˜¤ë¥˜:', error);
    throw error;
  }
}

// Float32 â†’ Int16 ë³€í™˜
function convertToPCM16(float32Array) {
  const int16Array = new Int16Array(float32Array.length);
  
  for (let i = 0; i < float32Array.length; i++) {
    // -1.0 ~ 1.0 â†’ -32768 ~ 32767
    const s = Math.max(-1, Math.min(1, float32Array[i]));
    int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }
  
  return int16Array;
}

// ArrayBuffer â†’ Base64 ë³€í™˜
function arrayBufferToBase64(buffer) {
  const bytes = new Uint8Array(buffer);
  let binary = '';
  for (let i = 0; i < bytes.length; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}
```

### 4. ë…¹ìŒ ì¤‘ì§€ ë° ì •ë¦¬

```javascript
function stopRecording() {
  // ì„œë²„ì— ì¤‘ì§€ ì‹ í˜¸ ì „ì†¡
  if (ws && ws.readyState === WebSocket.OPEN) {
    ws.send(JSON.stringify({ type: 'stop' }));
  }
  
  cleanup();
}

function cleanup() {
  // AudioContext ì •ë¦¬
  if (processor) {
    processor.disconnect();
    processor = null;
  }
  
  if (audioContext) {
    audioContext.close();
    audioContext = null;
  }
  
  // MediaStream ì •ë¦¬
  if (mediaStream) {
    mediaStream.getTracks().forEach(track => track.stop());
    mediaStream = null;
  }
  
  // WebSocket ì •ë¦¬
  if (ws) {
    ws.close();
    ws = null;
  }
}
```

---

## âš›ï¸ React í†µí•© ì˜ˆì œ

### 1. useSTT ì»¤ìŠ¤í…€ í›…

```jsx
import { useState, useRef, useCallback } from 'react';

function useSTT(wsUrl = 'ws://localhost:8003/ws/stt') {
  const [transcript, setTranscript] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [error, setError] = useState(null);
  
  const wsRef = useRef(null);
  const audioContextRef = useRef(null);
  const processorRef = useRef(null);
  const mediaStreamRef = useRef(null);
  
  // ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    try {
      setError(null);
      
      // WebSocket ì—°ê²°
      wsRef.current = new WebSocket(wsUrl);
      
      wsRef.current.onopen = async () => {
        setIsConnected(true);
        
        // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 24000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          }
        });
        
        mediaStreamRef.current = stream;
        
        // AudioContext ìƒì„±
        audioContextRef.current = new AudioContext({ sampleRate: 24000 });
        const source = audioContextRef.current.createMediaStreamSource(stream);
        processorRef.current = audioContextRef.current.createScriptProcessor(4096, 1, 1);
        
        // ì˜¤ë””ì˜¤ ì²˜ë¦¬
        processorRef.current.onaudioprocess = (e) => {
          const inputData = e.inputBuffer.getChannelData(0);
          const pcm16 = new Int16Array(inputData.length);
          
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }
          
          const base64 = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));
          
          if (wsRef.current?.readyState === WebSocket.OPEN) {
            wsRef.current.send(JSON.stringify({ type: 'audio', audio: base64 }));
          }
        };
        
        source.connect(processorRef.current);
        processorRef.current.connect(audioContextRef.current.destination);
        
        setIsRecording(true);
      };
      
      wsRef.current.onmessage = (event) => {
        const data = JSON.parse(event.data);
        
        if (data.type === 'transcript_completed') {
          setTranscript(prev => prev + data.text + '\n');
        } else if (data.type === 'error') {
          setError(data.message);
        }
      };
      
      wsRef.current.onerror = (err) => {
        setError('WebSocket ì—°ê²° ì˜¤ë¥˜');
        console.error(err);
      };
      
      wsRef.current.onclose = () => {
        setIsConnected(false);
        setIsRecording(false);
      };
      
    } catch (err) {
      setError(err.message);
      console.error(err);
    }
  }, [wsUrl]);
  
  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: 'stop' }));
    }
    
    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    processorRef.current?.disconnect();
    audioContextRef.current?.close();
    mediaStreamRef.current?.getTracks().forEach(track => track.stop());
    wsRef.current?.close();
    
    setIsRecording(false);
  }, []);
  
  // ì „ì‚¬ ë‚´ìš© ì´ˆê¸°í™”
  const clearTranscript = useCallback(() => {
    setTranscript('');
  }, []);
  
  return {
    transcript,
    isRecording,
    isConnected,
    error,
    startRecording,
    stopRecording,
    clearTranscript
  };
}

export default useSTT;
```

### 2. STT ì»´í¬ë„ŒíŠ¸

```jsx
import React from 'react';
import useSTT from './useSTT';

function STTComponent() {
  const {
    transcript,
    isRecording,
    isConnected,
    error,
    startRecording,
    stopRecording,
    clearTranscript
  } = useSTT();
  
  return (
    <div style={{ padding: '20px' }}>
      <h1>ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹</h1>
      
      {/* ìƒíƒœ í‘œì‹œ */}
      <div style={{ marginBottom: '20px' }}>
        ìƒíƒœ: {isRecording ? 'ğŸ”´ ë…¹ìŒ ì¤‘' : isConnected ? 'ğŸŸ¢ ì—°ê²°ë¨' : 'âšª ì—°ê²° ì•ˆë¨'}
      </div>
      
      {/* ì˜¤ë¥˜ í‘œì‹œ */}
      {error && (
        <div style={{ color: 'red', marginBottom: '20px' }}>
          âŒ {error}
        </div>
      )}
      
      {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ */}
      <div style={{ marginBottom: '20px' }}>
        <button 
          onClick={startRecording} 
          disabled={isRecording}
          style={{ marginRight: '10px' }}
        >
          ë…¹ìŒ ì‹œì‘
        </button>
        <button 
          onClick={stopRecording} 
          disabled={!isRecording}
          style={{ marginRight: '10px' }}
        >
          ë…¹ìŒ ì¤‘ì§€
        </button>
        <button onClick={clearTranscript}>
          ë‚´ìš© ì§€ìš°ê¸°
        </button>
      </div>
      
      {/* ì „ì‚¬ ê²°ê³¼ */}
      <div style={{
        border: '1px solid #ccc',
        borderRadius: '5px',
        padding: '15px',
        minHeight: '200px',
        backgroundColor: '#f9f9f9',
        whiteSpace: 'pre-wrap'
      }}>
        {transcript || 'ì „ì‚¬ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤...'}
      </div>
    </div>
  );
}

export default STTComponent;
```

---

## ğŸ­ Vue.js í†µí•© ì˜ˆì œ

### 1. useSTT Composable

```javascript
// composables/useSTT.js
import { ref } from 'vue';

export function useSTT(wsUrl = 'ws://localhost:8003/ws/stt') {
  const transcript = ref('');
  const isRecording = ref(false);
  const isConnected = ref(false);
  const error = ref(null);
  
  let ws = null;
  let audioContext = null;
  let processor = null;
  let mediaStream = null;
  
  const startRecording = async () => {
    try {
      error.value = null;
      
      // WebSocket ì—°ê²°
      ws = new WebSocket(wsUrl);
      
      ws.onopen = async () => {
        isConnected.value = true;
        
        // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 24000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          }
        });
        
        // AudioContext ìƒì„±
        audioContext = new AudioContext({ sampleRate: 24000 });
        const source = audioContext.createMediaStreamSource(mediaStream);
        processor = audioContext.createScriptProcessor(4096, 1, 1);
        
        // ì˜¤ë””ì˜¤ ì²˜ë¦¬
        processor.onaudioprocess = (e) => {
          const inputData = e.inputBuffer.getChannelData(0);
          const pcm16 = new Int16Array(inputData.length);
          
          for (let i = 0; i < inputData.length; i++) {
            const s = Math.max(-1, Math.min(1, inputData[i]));
            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }
          
          const base64 = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));
          
          if (ws?.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify({ type: 'audio', audio: base64 }));
          }
        };
        
        source.connect(processor);
        processor.connect(audioContext.destination);
        
        isRecording.value = true;
      };
      
      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        
        if (data.type === 'transcript_completed') {
          transcript.value += data.text + '\n';
        } else if (data.type === 'error') {
          error.value = data.message;
        }
      };
      
      ws.onerror = (err) => {
        error.value = 'WebSocket ì—°ê²° ì˜¤ë¥˜';
        console.error(err);
      };
      
      ws.onclose = () => {
        isConnected.value = false;
        isRecording.value = false;
      };
      
    } catch (err) {
      error.value = err.message;
      console.error(err);
    }
  };
  
  const stopRecording = () => {
    if (ws?.readyState === WebSocket.OPEN) {
      ws.send(JSON.stringify({ type: 'stop' }));
    }
    
    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    processor?.disconnect();
    audioContext?.close();
    mediaStream?.getTracks().forEach(track => track.stop());
    ws?.close();
    
    isRecording.value = false;
  };
  
  const clearTranscript = () => {
    transcript.value = '';
  };
  
  return {
    transcript,
    isRecording,
    isConnected,
    error,
    startRecording,
    stopRecording,
    clearTranscript
  };
}
```

### 2. Vue ì»´í¬ë„ŒíŠ¸

```vue
<template>
  <div class="stt-container">
    <h1>ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹</h1>
    
    <!-- ìƒíƒœ í‘œì‹œ -->
    <div class="status">
      ìƒíƒœ: 
      <span v-if="isRecording">ğŸ”´ ë…¹ìŒ ì¤‘</span>
      <span v-else-if="isConnected">ğŸŸ¢ ì—°ê²°ë¨</span>
      <span v-else>âšª ì—°ê²° ì•ˆë¨</span>
    </div>
    
    <!-- ì˜¤ë¥˜ í‘œì‹œ -->
    <div v-if="error" class="error">
      âŒ {{ error }}
    </div>
    
    <!-- ì»¨íŠ¸ë¡¤ ë²„íŠ¼ -->
    <div class="controls">
      <button @click="startRecording" :disabled="isRecording">
        ë…¹ìŒ ì‹œì‘
      </button>
      <button @click="stopRecording" :disabled="!isRecording">
        ë…¹ìŒ ì¤‘ì§€
      </button>
      <button @click="clearTranscript">
        ë‚´ìš© ì§€ìš°ê¸°
      </button>
    </div>
    
    <!-- ì „ì‚¬ ê²°ê³¼ -->
    <div class="transcript">
      {{ transcript || 'ì „ì‚¬ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤...' }}
    </div>
  </div>
</template>

<script setup>
import { useSTT } from '@/composables/useSTT';

const {
  transcript,
  isRecording,
  isConnected,
  error,
  startRecording,
  stopRecording,
  clearTranscript
} = useSTT();
</script>

<style scoped>
.stt-container {
  padding: 20px;
}

.status {
  margin: 20px 0;
  font-size: 1.2em;
}

.error {
  color: red;
  margin: 20px 0;
}

.controls {
  margin: 20px 0;
}

.controls button {
  margin-right: 10px;
  padding: 10px 20px;
  font-size: 1em;
}

.transcript {
  border: 1px solid #ccc;
  border-radius: 5px;
  padding: 15px;
  min-height: 200px;
  background-color: #f9f9f9;
  white-space: pre-wrap;
}
</style>
```

---

## âŒ ì˜¤ë¥˜ ì²˜ë¦¬

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë° í•´ê²° ë°©ë²•

```javascript
function handleError(error) {
  if (error instanceof DOMException) {
    switch (error.name) {
      case 'NotAllowedError':
        console.error('âŒ ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.');
        alert('ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        break;
        
      case 'NotFoundError':
        console.error('âŒ ë§ˆì´í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        alert('ë§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.');
        break;
        
      case 'NotReadableError':
        console.error('âŒ ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        alert('ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë§ˆì´í¬ë¥¼ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
        break;
        
      default:
        console.error('âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜:', error);
        alert('ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + error.message);
    }
  } else {
    console.error('âŒ ì˜¤ë¥˜:', error);
    alert('ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + error.message);
  }
}
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. ì˜¤ë””ì˜¤ ë²„í¼ í¬ê¸° ì¡°ì •

```javascript
// ë‚®ì€ ì§€ì—°ì‹œê°„ (ë” ë§ì€ CPU ì‚¬ìš©)
const processor = audioContext.createScriptProcessor(2048, 1, 1);

// ê· í˜• (ê¶Œì¥)
const processor = audioContext.createScriptProcessor(4096, 1, 1);

// ë†’ì€ ì²˜ë¦¬ëŸ‰ (ë” ë†’ì€ ì§€ì—°ì‹œê°„)
const processor = audioContext.createScriptProcessor(8192, 1, 1);
```

### 2. ë°°ì¹˜ ì „ì†¡

```javascript
let audioBuffer = [];
const BATCH_SIZE = 5;

processor.onaudioprocess = (e) => {
  const base64 = processAudio(e);
  audioBuffer.push(base64);
  
  // 5ê°œì”© ëª¨ì•„ì„œ ì „ì†¡
  if (audioBuffer.length >= BATCH_SIZE) {
    ws.send(JSON.stringify({
      type: 'audio_batch',
      chunks: audioBuffer
    }));
    audioBuffer = [];
  }
};
```

### 3. Worker ì‚¬ìš©

```javascript
// audio-worker.js
self.onmessage = (e) => {
  const { inputData } = e.data;
  
  // Float32 â†’ Int16 ë³€í™˜
  const pcm16 = new Int16Array(inputData.length);
  for (let i = 0; i < inputData.length; i++) {
    const s = Math.max(-1, Math.min(1, inputData[i]));
    pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }
  
  // Base64 ì¸ì½”ë”©
  const base64 = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));
  
  self.postMessage({ base64 });
};
```

---

## â“ FAQ

### Q1: ì™œ ìƒ˜í”Œë ˆì´íŠ¸ê°€ ë°˜ë“œì‹œ 24kHzì—¬ì•¼ í•˜ë‚˜ìš”?

**A**: OpenAI Realtime APIì˜ ìš”êµ¬ì‚¬í•­ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ìƒ˜í”Œë ˆì´íŠ¸ë¥¼ ì‚¬ìš©í•˜ë©´ ì „ì‚¬ í’ˆì§ˆì´ ì €í•˜ë˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Q2: VADë¥¼ ë¹„í™œì„±í™”í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?

**A**: ì„œë²„ì˜ `.env` íŒŒì¼ì—ì„œ `VAD_ENABLED=false`ë¡œ ì„¤ì •í•˜ì„¸ìš”. VAD ë¹„í™œì„±í™” ì‹œ ì£¼ê¸°ì ìœ¼ë¡œ ì˜¤ë””ì˜¤ë¥¼ ì»¤ë°‹í•´ì•¼ í•©ë‹ˆë‹¤.

### Q3: HTTPSê°€ í•„ìš”í•œê°€ìš”?

**A**: ë¡œì»¬ í…ŒìŠ¤íŠ¸(`localhost`)ì—ì„œëŠ” HTTPë„ ê°€ëŠ¥í•˜ì§€ë§Œ, í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” HTTPSê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.

### Q4: ëª¨ë°”ì¼ì—ì„œë„ ì‘ë™í•˜ë‚˜ìš”?

**A**: ë„¤, ëª¨ë°”ì¼ ë¸Œë¼ìš°ì €(Chrome, Safari)ì—ì„œë„ ì‘ë™í•©ë‹ˆë‹¤. ë‹¨, HTTPS í™˜ê²½ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

### Q5: ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ê°€ ë™ì‹œì— ì—°ê²°í•  ìˆ˜ ìˆë‚˜ìš”?

**A**: ë„¤, ê° í´ë¼ì´ì–¸íŠ¸ëŠ” ë…ë¦½ì ì¸ ì„¸ì…˜ì„ ê°€ì§‘ë‹ˆë‹¤.

---

**ë¬¸ì˜ì‚¬í•­ì´ ìˆìœ¼ë©´ íŒ€ì— ì—°ë½í•˜ì„¸ìš”! ğŸ“**
