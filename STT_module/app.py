"""
STT FastAPI ì„œë²„
í”„ë¡ íŠ¸ì—”ë“œ íŒ€ í…ŒìŠ¤íŠ¸ìš© ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì„œë²„
"""
import asyncio
import logging
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
import uvicorn

from config import HOST, PORT, VAD_ENABLED, LOG_LEVEL, WEBSOCKET_ENDPOINT
from stt_session import RealtimeSTTSession

# ===========================
# ğŸ“Š ë¡œê¹… ì„¤ì •
# ===========================
logging.basicConfig(
    level=getattr(logging, LOG_LEVEL),
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ===========================
# ğŸš€ FastAPI ì•± ìƒì„±
# ===========================
app = FastAPI(
    title="STT Server",
    description="ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì„œë²„ (OpenAI Realtime API)",
    version="1.0.0"
)

# ===========================
# ğŸ“„ ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸
# ===========================
@app.get("/")
async def root():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "running",
        "message": "âœ… STT ì„œë²„ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "endpoints": {
            "websocket": f"ws://{HOST}:{PORT}{WEBSOCKET_ENDPOINT}",
            "test_page": f"http://{HOST}:{PORT}/test"
        }
    }

# ===========================
# ğŸ§ª í…ŒìŠ¤íŠ¸ í˜ì´ì§€
# ===========================
@app.get("/test", response_class=HTMLResponse)
async def test_page():
    """ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ í˜ì´ì§€"""
    return """
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>STT í…ŒìŠ¤íŠ¸</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            margin-bottom: 10px;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        .status.disconnected { background: #ffebee; color: #c62828; }
        .status.connected { background: #e8f5e9; color: #2e7d32; }
        .status.recording { background: #fff3e0; color: #e65100; }
        button {
            padding: 12px 24px;
            margin: 5px;
            border: none;
            border-radius: 5px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
        }
        button:hover { transform: translateY(-2px); }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
        #startBtn { background: #4CAF50; color: white; }
        #stopBtn { background: #f44336; color: white; }
        #transcriptArea {
            width: 100%;
            height: 300px;
            margin-top: 20px;
            padding: 15px;
            border: 2px solid #ddd;
            border-radius: 5px;
            font-family: monospace;
            font-size: 14px;
            resize: vertical;
        }
        .info {
            background: #e3f2fd;
            padding: 15px;
            border-radius: 5px;
            margin: 20px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤ STT ì„œë²„ í…ŒìŠ¤íŠ¸</h1>
        <div id="statusDiv" class="status disconnected">ğŸ”´ ì—°ê²°ë˜ì§€ ì•ŠìŒ</div>
        
        <div style="margin: 20px 0;">
            <button id="startBtn" onclick="startRecording()">ğŸ™ï¸ ë…¹ìŒ ì‹œì‘</button>
            <button id="stopBtn" onclick="stopRecording()" disabled>â¹ï¸ ë…¹ìŒ ì¤‘ì§€</button>
        </div>
        
        <div class="info">
            <strong>ğŸ“‹ ì‚¬ìš© ë°©ë²•:</strong><br>
            1. "ë…¹ìŒ ì‹œì‘" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”<br>
            2. ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•˜ì„¸ìš”<br>
            3. í•œêµ­ì–´ë¡œ ë§í•˜ì„¸ìš”<br>
            4. ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì‚¬ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤<br>
            5. ì™„ë£Œë˜ë©´ "ë…¹ìŒ ì¤‘ì§€"ë¥¼ í´ë¦­í•˜ì„¸ìš”
        </div>
        
        <textarea id="transcriptArea" readonly placeholder="ì „ì‚¬ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤..."></textarea>
    </div>

    <script>
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let isRecording = false;

        function updateStatus(text, className) {
            const statusDiv = document.getElementById('statusDiv');
            statusDiv.textContent = text;
            statusDiv.className = 'status ' + className;
        }

        function appendTranscript(text, isDelta = false) {
            const area = document.getElementById('transcriptArea');
            if (isDelta) {
                // ë¸íƒ€ëŠ” í˜„ì¬ ì¤„ì— ì¶”ê°€
                const lines = area.value.split('\\n');
                lines[lines.length - 1] += text;
                area.value = lines.join('\\n');
            } else {
                // ì™„ë£Œëœ ì „ì‚¬ëŠ” ìƒˆ ì¤„ë¡œ
                area.value += text + '\\n';
            }
            area.scrollTop = area.scrollHeight;
        }

        async function startRecording() {
            try {
                updateStatus('ğŸ”„ ì—°ê²° ì¤‘...', 'connected');
                
                // WebSocket ì—°ê²°
                ws = new WebSocket(`ws://${window.location.host}/ws/stt`);
                
                ws.onopen = async () => {
                    updateStatus('ğŸŸ¢ ì—°ê²°ë¨ - ë…¹ìŒ ì¤€ë¹„ ì¤‘...', 'connected');
                    
                    // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
                    const stream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            channelCount: 1,
                            sampleRate: 24000,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    // AudioContext ìƒì„±
                    audioContext = new AudioContext({ sampleRate: 24000 });
                    const source = audioContext.createMediaStreamSource(stream);
                    const processor = audioContext.createScriptProcessor(4096, 1, 1);
                    
                    processor.onaudioprocess = (e) => {
                        if (!isRecording) return;
                        
                        const inputData = e.inputBuffer.getChannelData(0);
                        const pcm16 = new Int16Array(inputData.length);
                        
                        for (let i = 0; i < inputData.length; i++) {
                            const s = Math.max(-1, Math.min(1, inputData[i]));
                            pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                        }
                        
                        // Base64 ì¸ì½”ë”©
                        const base64 = btoa(String.fromCharCode.apply(null, new Uint8Array(pcm16.buffer)));
                        
                        // WebSocketìœ¼ë¡œ ì „ì†¡
                        if (ws && ws.readyState === WebSocket.OPEN) {
                            ws.send(JSON.stringify({
                                type: 'audio',
                                audio: base64
                            }));
                        }
                    };
                    
                    source.connect(processor);
                    processor.connect(audioContext.destination);
                    
                    isRecording = true;
                    updateStatus('ğŸ”´ ë…¹ìŒ ì¤‘...', 'recording');
                    document.getElementById('startBtn').disabled = true;
                    document.getElementById('stopBtn').disabled = false;
                };
                
                ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    
                    if (data.type === 'transcript_delta') {
                        appendTranscript(data.text, true);
                    } else if (data.type === 'transcript_completed') {
                        appendTranscript('\\nâœ… ' + data.text + '\\n');
                    } else if (data.type === 'error') {
                        appendTranscript('\\nâŒ ì˜¤ë¥˜: ' + data.message + '\\n');
                    } else if (data.type === 'speech_started') {
                        appendTranscript('\\nğŸ¤ [ìŒì„± ê°ì§€ ì‹œì‘]\\n');
                    } else if (data.type === 'speech_stopped') {
                        appendTranscript('\\nâ¸ï¸ [ìŒì„± ê°ì§€ ì¢…ë£Œ]\\n');
                    } else if (data.type === 'info') {
                        console.log('â„¹ï¸', data.message);
                    }
                };
                
                ws.onerror = (error) => {
                    console.error('WebSocket ì˜¤ë¥˜:', error);
                    updateStatus('âŒ ì—°ê²° ì˜¤ë¥˜', 'disconnected');
                };
                
                ws.onclose = () => {
                    updateStatus('ğŸ”´ ì—°ê²° ì¢…ë£Œë¨', 'disconnected');
                    isRecording = false;
                    document.getElementById('startBtn').disabled = false;
                    document.getElementById('stopBtn').disabled = true;
                };
                
            } catch (error) {
                console.error('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', error);
                alert('ì˜¤ë¥˜: ' + error.message);
                updateStatus('âŒ ì˜¤ë¥˜ ë°œìƒ', 'disconnected');
            }
        }

        function stopRecording() {
            isRecording = false;
            
            if (ws) {
                ws.send(JSON.stringify({ type: 'stop' }));
                setTimeout(() => ws.close(), 500);
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            updateStatus('ğŸŸ¡ ë…¹ìŒ ì¤‘ì§€ë¨', 'connected');
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }
    </script>
</body>
</html>
    """

# ===========================
# ğŸ”Œ WebSocket ì—”ë“œí¬ì¸íŠ¸
# ===========================
@app.websocket(WEBSOCKET_ENDPOINT)
async def websocket_stt(websocket: WebSocket):
    """
    ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ WebSocket ì—”ë“œí¬ì¸íŠ¸
    
    ë©”ì‹œì§€ í˜•ì‹:
    - í´ë¼ì´ì–¸íŠ¸ â†’ ì„œë²„:
        {"type": "audio", "audio": "<base64-encoded-pcm16>"}
        {"type": "stop"}
    
    - ì„œë²„ â†’ í´ë¼ì´ì–¸íŠ¸:
        {"type": "transcript_delta", "text": "...", "item_id": "...", "timestamp": "..."}
        {"type": "transcript_completed", "text": "...", "item_id": "...", "timestamp": "..."}
        {"type": "speech_started", "timestamp": "..."}
        {"type": "speech_stopped", "timestamp": "..."}
        {"type": "error", "message": "..."}
        {"type": "info", "message": "..."}
    """
    await websocket.accept()
    client_id = id(websocket)
    logger.info(f"âœ… í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ë¨ (ID: {client_id})")
    
    session = RealtimeSTTSession(websocket)
    chunk_count = 0
    
    try:
        # OpenAI Realtime API ì—°ê²°
        if not await session.connect_to_openai():
            await websocket.send_json({
                "type": "error",
                "message": "OpenAI Realtime API ì—°ê²° ì‹¤íŒ¨"
            })
            return
        
        # OpenAI ì´ë²¤íŠ¸ ìˆ˜ì‹  íƒœìŠ¤í¬ ì‹œì‘
        listen_task = asyncio.create_task(session.listen_openai_events())
        
        # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ìˆ˜ì‹ 
        while True:
            data = await websocket.receive_json()
            
            if data.get("type") == "audio":
                # ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡
                audio_base64 = data.get("audio", "")
                
                if audio_base64:
                    chunk_count += 1
                    await session.send_audio(audio_base64)
                    
                    # VAD ë¯¸ì‚¬ìš© ì‹œ ì£¼ê¸°ì ìœ¼ë¡œ ì»¤ë°‹
                    if not VAD_ENABLED and chunk_count % 5 == 0:  # 1ì´ˆë§ˆë‹¤ (200ms * 5)
                        await session.commit_audio()
            
            elif data.get("type") == "stop":
                logger.info(f"ğŸ›‘ ë…¹ìŒ ì¤‘ì§€ ìš”ì²­ (í´ë¼ì´ì–¸íŠ¸ {client_id})")
                
                # ë§ˆì§€ë§‰ ì˜¤ë””ì˜¤ ì»¤ë°‹
                if not VAD_ENABLED:
                    await session.commit_audio()
                
                await websocket.send_json({
                    "type": "info",
                    "message": "âœ… ë…¹ìŒ ì¢…ë£Œ"
                })
                break
                        
    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ëŠê¹€ (ID: {client_id})")
    except Exception as e:
        logger.error(f"âŒ WebSocket ì˜¤ë¥˜ (í´ë¼ì´ì–¸íŠ¸ {client_id}): {e}", exc_info=True)
        try:
            await websocket.send_json({
                "type": "error",
                "message": f"ì„œë²„ ì˜¤ë¥˜: {str(e)}"
            })
        except:
            pass
    finally:
        await session.close()
        if 'listen_task' in locals():
            listen_task.cancel()
        logger.info(f"ğŸ”š ì„¸ì…˜ ì¢…ë£Œ (í´ë¼ì´ì–¸íŠ¸ {client_id}, ì´ {chunk_count}ê°œ ì²­í¬ ì²˜ë¦¬)")


# ===========================
# ğŸƒ ì„œë²„ ì‹¤í–‰
# ===========================
if __name__ == "__main__":
    logger.info("=" * 60)
    logger.info("ğŸš€ STT ì„œë²„ ì‹œì‘")
    logger.info(f"ğŸ“ ì£¼ì†Œ: http://{HOST}:{PORT}")
    logger.info(f"ğŸ”Œ WebSocket: ws://{HOST}:{PORT}{WEBSOCKET_ENDPOINT}")
    logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ í˜ì´ì§€: http://{HOST}:{PORT}/test")
    logger.info(f"ğŸ¯ VAD í™œì„±í™”: {VAD_ENABLED}")
    logger.info("=" * 60)
    
    uvicorn.run(
        app,
        host=HOST,
        port=PORT,
        log_level=LOG_LEVEL.lower()
    )
